# -*- coding: utf-8 -*-
"""segformertf.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nW7zVitXDG-3WlgD43l2DGlWS4DnHHO5
"""

import tensorflow as tf

gpus = tf.config.list_physical_devices('GPU')
if gpus and len(gpus) > 1:
    try:
        # Set only GPU 1 to be visible
        tf.config.set_visible_devices(gpus[1], 'GPU')

        # Optional: set memory growth
        tf.config.experimental.set_memory_growth(gpus[1], True)

    except RuntimeError as e:
        print(e)

import tensorflow as tf
AUTOTUNE = tf.data.experimental.AUTOTUNE
import glob
import os

class data_preprocess:
  def __init__(self, image_dir, label_dir, batch_size=8, shuffle=True, augment=True):
    self.image_dir = image_dir
    self.label_dir = label_dir

    self.batch_size = batch_size
    self.shuffle = shuffle
    self.augment = augment

    self.mean = tf.constant([0.485, 0.456, 0.406])
    self.std = tf.constant([0.229, 0.224, 0.225])

    self.image_paths = sorted(glob.glob(os.path.join(self.image_dir, '*')))
    self.label_paths = sorted(glob.glob(os.path.join(self.label_dir, '*')))

    assert len(self.image_paths) == len(self.label_paths), "Image and Label count mismatch"


  def load_image_label(self,image_path,label_path):
    img = tf.io.read_file(image_path)
    img = tf.image.decode_jpeg(img, channels=3)
    img = tf.image.convert_image_dtype(img, tf.float32)

    label = tf.io.read_file(label_path)
    label = tf.image.decode_jpeg(label, channels=3)
    label = tf.image.convert_image_dtype(label, tf.float32)

    return img,label
  def preprocess(self, img, label):
    if self.augment:
        img, label = self.random_flip(img, label)
        img, label = self.random_crop_resize(img, label, crop_size=(448,448))

    img = (img - self.mean) / self.std
    return img, label
  def random_flip(self, img, label):
    if tf.random.uniform([]) > 0.5:
        img = tf.image.flip_left_right(img)
        label = tf.image.flip_left_right(label)
    return img, label

  def random_crop_resize(self, img, label, crop_size):
    combined = tf.concat([img, tf.cast(label, tf.float32)], axis=-1)
    combined = tf.image.resize_with_crop_or_pad(combined, 500, 500)
    combined = tf.image.random_crop(combined, size=[crop_size[0], crop_size[1], 4])

    img = combined[..., :3]
    label = tf.cast(combined[..., 3:], tf.int32)
    return img, label

  def build_dataset(self):
    ds = tf.data.Dataset.from_tensor_slices((self.image_paths, self.label_paths))

    if self.shuffle:
        ds = ds.shuffle(buffer_size=len(self.image_paths))

    ds = ds.map(lambda img, lbl: self.load_image_label(img, lbl), num_parallel_calls=AUTOTUNE)
    ds = ds.map(lambda img, lbl: self.preprocess(img, lbl), num_parallel_calls=AUTOTUNE)
    ds = ds.batch(self.batch_size).prefetch(AUTOTUNE)

    return ds

train_dataset = data_preprocess(
    image_dir='/mnt/data/Kushal/cracks/train/images',
    label_dir='/mnt/data/Kushal/cracks/train/masks',
    batch_size=4,
    augment=True
).build_dataset()

valid_dataset = data_preprocess(
    image_dir='/mnt/data/Kushal/cracks/test/images',
    label_dir='/mnt/data/Kushal/cracks/test/masks',
    batch_size=4,
    augment = True
).build_dataset()

for imgs, labels in valid_dataset.take(1):
    print(imgs.shape, labels.shape)

for imgs, labels in train_dataset.take(1):
    print(imgs.shape, labels.shape)

import tensorflow as tf
from tensorflow.keras.optimizers import Adam

def iou_metric(y_true, y_pred, threshold=0.5):
    """Calculate Intersection over Union (IoU) for binary classification."""
    # Flatten the images
    y_true_f = tf.reshape(tf.cast(y_true, tf.float32), [-1])  # Cast y_true to float32
    y_pred_f = tf.reshape(tf.cast(y_pred > threshold, tf.float32), [-1])

    # Calculate intersection and union
    intersection = tf.reduce_sum(y_true_f * y_pred_f)
    union = tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) - intersection

    # Avoid division by zero
    iou = intersection / (union + tf.keras.backend.epsilon())
    return iou

import tensorflow as tf
from tensorflow.keras import layers, models

input_size = (448,448, 3)
inputs = layers.Input(input_size)

def aggregate(l1, l2, l3, l4, l5):
    out = layers.Concatenate(axis=-1)([l1, l2, l3, l4, l5])
    out = layers.Conv2D(320, 3, activation='relu', padding='same', kernel_initializer='he_normal')(out)
    out = layers.BatchNormalization()(out)
    out = layers.ReLU()(out)
    return out

base_channel = 16

def unet3plus(inputs, conv_num=base_channel):
    XE1 = layers.Conv2D(conv_num, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)
    XE1 = layers.Conv2D(conv_num, 3, activation='relu', padding='same', kernel_initializer='he_normal')(XE1)
    XE1_pool = layers.MaxPooling2D(pool_size=(2, 2))(XE1)

    XE2 = layers.Conv2D(conv_num * 2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(XE1_pool)
    XE2 = layers.Conv2D(conv_num * 2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(XE2)
    XE2 = layers.Dropout(0.2)(XE2)   # this is extra dropout
    XE2_pool = layers.MaxPooling2D(pool_size=(2, 2))(XE2)

    XE3 = layers.Conv2D(conv_num * 4, 3, activation='relu', padding='same', kernel_initializer='he_normal')(XE2_pool)
    XE3 = layers.Conv2D(conv_num * 4, 3, activation='relu', padding='same', kernel_initializer='he_normal')(XE3)
    XE3 = layers.Dropout(0.2)(XE3)   #this is extra dropout
    XE3_pool = layers.MaxPooling2D(pool_size=(2, 2))(XE3)

    XE4 = layers.Conv2D(conv_num * 8, 3, activation='relu', padding='same', kernel_initializer='he_normal')(XE3_pool)
    XE4 = layers.Conv2D(conv_num * 8, 3, activation='relu', padding='same', kernel_initializer='he_normal')(XE4)
    XE4 = layers.Dropout(0.5)(XE4)
    XE4_pool = layers.MaxPooling2D(pool_size=(2, 2))(XE4)

    XE5 = layers.Conv2D(conv_num * 16, 3, activation='relu', padding='same', kernel_initializer='he_normal')(XE4_pool)
    XE5 = layers.Conv2D(conv_num * 16, 3, activation='relu', padding='same', kernel_initializer='he_normal')(XE5)
    XE5 = layers.Dropout(0.5)(XE5)

    XD1_from_XE5 = layers.UpSampling2D(size=(16, 16), interpolation='bilinear')(XE5)
    XD1_from_XE5 = layers.Conv2D(conv_num, 3, activation='relu', padding='same', kernel_initializer='he_normal')(XD1_from_XE5)
    XD1_from_XE4 = layers.UpSampling2D(size=(8, 8), interpolation='bilinear')(XE4)
    XD1_from_XE4 = layers.Conv2D(conv_num, 3, activation='relu', padding='same', kernel_initializer='he_normal')(XD1_from_XE4)
    XD1_from_XE3 = layers.UpSampling2D(size=(4, 4), interpolation='bilinear')(XE3)
    XD1_from_XE3 = layers.Conv2D(conv_num, 3, activation='relu', padding='same', kernel_initializer='he_normal')(XD1_from_XE3)
    XD1_from_XE2 = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(XE2)
    XD1_from_XE2 = layers.Conv2D(conv_num, 3, activation='relu', padding='same', kernel_initializer='he_normal')(XD1_from_XE2)
    XD1_from_XE1 = layers.Conv2D(conv_num, 3, activation='relu', padding='same', kernel_initializer='he_normal')(XE1)
    XD1 = aggregate(XD1_from_XE5, XD1_from_XE4, XD1_from_XE3, XD1_from_XE2, XD1_from_XE1)

    out = layers.Conv2D(conv_num * 5, 3, activation='sigmoid', padding='same', kernel_initializer='he_normal')(XD1)
    out = layers.Conv2D(1, 3, activation='sigmoid', padding='same', kernel_initializer='he_normal')(out)
    print(out.shape)
    return out

model = models.Model(inputs, unet3plus(inputs))

import tensorflow.keras.backend as K
import tensorflow as tf

def dice_loss(y_true, y_pred, smooth=1e-6):
    y_true_f = K.flatten(y_true)
    y_pred_f = K.flatten(y_pred)
    intersection = K.sum(y_true_f * y_pred_f)
    return 1 - (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)

def focal_loss(alpha=0.8, gamma=2.0):
    def loss(y_true, y_pred):
        y_true = K.flatten(y_true)
        y_pred = K.flatten(y_pred)
        bce = K.binary_crossentropy(y_true, y_pred)
        bce_exp = K.exp(-bce)
        focal = alpha * K.pow((1 - bce_exp), gamma) * bce
        return K.mean(focal)
    return loss

def combined_loss(alpha=0.8, gamma=2.0, dice_weight=0.5, focal_weight=0.5):
    def loss(y_true, y_pred):
        return dice_weight * dice_loss(y_true, y_pred) + focal_weight * focal_loss(alpha, gamma)(y_true, y_pred)
    return loss

# Compile the model with the combined loss
model.compile(optimizer="adam", loss=combined_loss(), metrics=["accuracy",iou_metric])

history = model.fit(train_dataset, epochs=10, validation_data=valid_dataset)



# model = tf.keras.models.load_model('my_model.h5') by this line you can load the model
from tensorflow import keras
model.save("my_model70.keras")  # Save as .keras file

model.save('my_model_20.h5')

